<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Vercel Serverless Functions vs Cloudflare Workers | Moiva.io Blog</title>
    <meta name="description" content="Detailed comparison of Vercel Serverless Functions and Cloudflare Workers. Which one is better?">
    <link rel="stylesheet" href="/blog/assets/style.16e8d4c2.css">
    <link rel="modulepreload" href="/blog/assets/app.c9d8ac17.js">
    <link rel="modulepreload" href="/blog/assets/vercel-serverless-functions-vs-cloudflare-workers_index.md.8e5a506b.lean.js">
    
    <script>!window.location.href.endsWith("/")&&!window.location.href.includes("#")&&window.location.assign(window.location.href+"/");</script>
  <link rel="icon" type="image/x-icon" href="/favicon/favicon.ico">
  <meta name="copyright" content="2020-current, Alexey Antipov">
  <meta name="twitter:creator" content="@_aantipov">
  <meta name="twitter:card" content="summary_large_image">
  <script async="true" defer="true" data-domain="moiva.io" src="https://plausible.io/js/plausible.js"></script>
  <meta property="og:description" content="Detailed comparison of Vercel Serverless Functions and Cloudflare Workers. Which one is better?">
  <meta name="twitter:description" content="Detailed comparison of Vercel Serverless Functions and Cloudflare Workers. Which one is better?">
  <meta property="og:image" content="https://moiva.io/images/moiva-head.jpg">
  <meta name="twitter:image" content="https://moiva.io/images/moiva-head.jpg">
  <meta property="og:url" content="https://moiva.io/blog/vercel-serverless-functions-vs-cloudflare-workers/">
  <meta property="twitter:url" content="https://moiva.io/blog/vercel-serverless-functions-vs-cloudflare-workers/">
  <link rel="canonical" href="https://moiva.io/blog/vercel-serverless-functions-vs-cloudflare-workers/">
  <meta name="twitter:title" content="Vercel Serverless Functions vs Cloudflare Workers | Moiva.io Blog">
  <meta property="og:title" content="Vercel Serverless Functions vs Cloudflare Workers | Moiva.io Blog">
  </head>
  <body>
    <div id="app"><div class="antialiased h-full flex flex-col"><div class="myprose flex-grow mb-8"><div class="container flex items-center sm:pt-4 mb-8 md:mb-16" data-v-3964f104><img src="/blog/assets/moiva-head.691f2c38.jpg" alt="Moiva.io logo" width="70" height="70" style="margin:0 20px 0 0;" class="inline md:hidden" data-v-3964f104><img src="/blog/assets/moiva-head.691f2c38.jpg" alt="Moiva.io logo" width="100" height="100" style="margin:0 20px 0 0;" class="hidden md:inline" data-v-3964f104><a href="/blog/" title="Home" class="sm:text-5xl text-4xl" data-v-3964f104> Moiva.io Blog </a></div><article class="container root" data-v-f61783ce><main data-v-f61783ce><div class="mb-2 h-9" data-v-f61783ce><!----></div><h1 data-v-f61783ce>Vercel Serverless Functions vs Cloudflare Workers</h1><div style="position:relative;" class="mt-6" data-v-f61783ce><div><div class="info custom-block"><p class="custom-block-title">Update 2021-05-11</p><p>Cloudflare released <a href="https://blog.cloudflare.com/workers-unbound-ga/" target="_blank" rel="noopener noreferrer">Workers Unboud</a> - a solution for serverless functions that need long excecution times. It extends the existing 50ms CPU limit to 30sec and changes their billing scheme.</p></div><div class="info custom-block"><p class="custom-block-title">Update 2021-03-29</p><p>Added an image of vercel edge network map. kudos to <a href="https://twitter.com/magnemg" target="_blank" rel="noopener noreferrer">@magnemg</a> for creating it.</p></div><h2 id="tldr" tabindex="-1">TLDR <a class="header-anchor" href="#tldr" aria-hidden="true">#</a></h2><p>Vercel provides a good solid solution for Serverless Functions and makes the process of their creation seamless and hassle-free. Cloudflare Workers offer more functionality out-of-the-box (e.g. key-value data store, CRON) and look more mature and sophisticated.</p><h2 id="before-we-proceed" tabindex="-1">Before we proceed <a class="header-anchor" href="#before-we-proceed" aria-hidden="true">#</a></h2><p>All my conclusions and findings are based on the official documentation provided by Vercel and Cloudflare and also based on my experience with both platforms. I reserve the right for mistakes. Please let me know if you find any.</p><h2 id="introduction" tabindex="-1">Introduction <a class="header-anchor" href="#introduction" aria-hidden="true">#</a></h2><p>I&#39;ve been using <a href="https://vercel.com/" target="_blank" rel="noopener noreferrer">Vercel</a> since the start of <a href="http://moiva.io" target="_blank" rel="noopener noreferrer">Moiva</a> development. It helped to bootstrap and develop Moiva fast. I&#39;m very grateful to the developers at Vercel, they do a great job there.</p><p><a href="https://vercel.com/" target="_blank" rel="noopener noreferrer">Vercel</a>, in the essence, is a solution for automatic deployments of static websites to a network of data-centers around the world. Vercel doesn&#39;t stop there and provides a solution for Serverless Functions which works really great and smooth.</p><p>With further development of Moiva I accumulated a set of requirements for Serverless Functions which Vercel, unfortunately, didn&#39;t meet. Hence I looked around and found <a href="https://workers.cloudflare.com/" target="_blank" rel="noopener noreferrer">Cloudflare Workers</a>. I gave it a try and I liked it. Two weeks later all my Serverless Functions were migrated there.</p><p><a href="https://workers.cloudflare.com/" target="_blank" rel="noopener noreferrer">Cloudflare Workers</a> is basically a platform for deployment of Serverless Functions to a network of data-centers around the world. Their documentation <a href="https://developers.cloudflare.com/workers/platform/sites" target="_blank" rel="noopener noreferrer">says</a> that Workers can also be used to deploy static applications as well, but I haven&#39;t looked into it or evaluated it. I know that Cloudflare is also working on another solution for deployment/hosting of static applications - <a href="https://pages.cloudflare.com/" target="_blank" rel="noopener noreferrer">Cloudflare Pages</a>.</p><p>I thought that my findings could be interested to others. Here we go!</p><h2 id="serverless-functions-requests-handling" tabindex="-1">Serverless Functions requests handling <a class="header-anchor" href="#serverless-functions-requests-handling" aria-hidden="true">#</a></h2><p>The high-level picture of how Serverless Functions requests are handled is different in Vercel and Cloudflare Workers. I think it makes sense to start the comparison with an explanation of how each platform works and highlighting the differences.</p><p>First of all, both platforms use a so-called Edge Network of thousands of servers distributed across the globe.</p><p>In <strong>Cloudflare Workers</strong> every Function during deployment gets replicated in every data center. Every request is load-balanced and routed to the nearest data center, which executes the Function and sends the response back to the user.</p><p><img src="/blog/assets/cloudflare.4fdc7655.png" alt=""></p><p>It&#39;s important to note here that Functions are executed on <strong>every</strong> request, even if the response has been cached. The cache works on a deeper more granular level:</p><ul><li>Function&#39;s outgoing sub-requests are cached automatically.</li><li>developers can utilize Cloudflare&#39;s <a href="https://developers.cloudflare.com/workers/runtime-apis/cache" target="_blank" rel="noopener noreferrer">Cache API</a> to cache the response and use it in further requests. It can be especially handy in case of heavy computations.</li></ul><p><strong>Vercel</strong> doesn&#39;t replicate Functions across their Network in Free and Pro accounts - Functions can be deployed to one particular region only. Enterprise plan users can specify multiple regions for Serverless Functions.</p><p>Similar to Cloudflare, every request is being routed to the nearest data center. Here similarities end and the following steps are being processed:</p><ol><li>If the data center has a cache for the request, then the cached response is sent back to the user immediately. The Function is not executed. The request processing is finished. <img src="/blog/assets/vercel-cached.ee387f68.png" alt=""></li><li>If the data center doesn&#39;t have the Function aboard, then it finds the nearest data center which has it and forwards the request there.</li><li>The Function is executed and the response is sent back to the original server.</li><li>The original server caches the response (according to headers specified by the developer) and sends the response back to the user. <img src="/blog/assets/vercel.c1e699e2.png" alt=""></li></ol><h2 id="requests-travel-time" tabindex="-1">Requests Travel Time <a class="header-anchor" href="#requests-travel-time" aria-hidden="true">#</a></h2><p>Speed is an important characteristic of Serverless Functions. It is measured by the time it takes to deliver the response to the user.</p><p>One of its constituents is Travel Time. The less time the request spends traveling the better.</p><p><strong>Cloudflare Workers</strong>, as we saw above, route every request to the nearest data center which processes it and sends the response back. Cloudflare <a href="https://www.cloudflare.com/network/" target="_blank" rel="noopener noreferrer">says</a> its Network spans over 200 cities in more than 100 countries. That guarantees the least Travel Time.</p><p><img src="/blog/assets/cloudflare-network.9f23abd8.png" alt=""></p><p><strong>Vercel</strong>&#39;s Network is significantly less dense and spans <a href="https://vercel.com/docs/edge-network/regions" target="_blank" rel="noopener noreferrer">less than 20 locations</a>. It means that on average requests will spend more time traveling. Moreover, requests will end on the nearest server only in the happy case of a pre-existing cache. Other times, as we saw above, the request will be forwarded further to the data center which contains the Function. It diminishes all advantages of having a global network of data centers.</p><p><img src="/blog/assets/vercel-network.91b60024.png" alt=""></p><h2 id="function-execution-time" tabindex="-1">Function Execution time <a class="header-anchor" href="#function-execution-time" aria-hidden="true">#</a></h2><p>Request/Function Execution Time is another major constituent of Speed. It largely depends on if there is cached data already or not.</p><p>As was already mentioned, Cache handling in Vercel and Cloudflare is done differently.</p><p>Cloudflare Worker always executes the Function whether or not there is cached data. Vercel, on the other hand, never executes the Function if it has valid cached data. We can imagine it affects Execution Time, but not significantly because Cloudflare limits it (see Limits section below for details).</p><p>In the absence of cached data, Execution Time depends on how fast the runtime environment is bootstrapped and on the available runtime resources like memory and CPU and if the Function is &quot;HOT&quot; or &quot;COLD&quot; (applies to Vercel only).</p><p><strong>Cloudflare</strong> uses Google&#39;s <a href="https://v8.dev/" target="_blank" rel="noopener noreferrer">V8 Engine</a> under the hood and executes Functions in the context of V8 Isolates. Cloudflare <a href="https://developers.cloudflare.com/workers/learning/how-workers-works#isolates" target="_blank" rel="noopener noreferrer">claims</a> that its approach is much more efficient than other Functions implementations and eliminates the cold starts of the virtual machine model:</p><blockquote><p>Workers processes are able to run essentially limitless scripts with almost no individual overhead by creating an isolate for each Workers function call. Any given isolate can start around a hundred times faster than a Node process on a container or virtual machine. Notably, on startup isolates consume an order of magnitude less memory.</p></blockquote><p><strong>Vercel</strong> uses Cloud Providers Amazon and Google to execute Functions and natively supports NodeJS, Go, Python, and Ruby environments. Hot/Cold boots apply here:</p><ul><li>If a subsequent request happens quickly thereafter, the function is re-used for a new invocation (Hot Boot)</li><li>Otherwise, the Function boots up from scratch (Cold Boot)</li></ul><p>Vercel <a href="https://vercel.com/docs/serverless-functions/conceptual-model#cold-and-hot-boots" target="_blank" rel="noopener noreferrer">says</a> that their configuration provides &quot;nearly instant&quot; cold boots:</p><blockquote><p>Cloud providers allow for a variety of different sized functions, but we have picked one that is aligned with making cold boot instantiation nearly instant for user-facing workloads (such as serving HTTP traffic)</p></blockquote><h2 id="dx-and-ease-of-development-deployment" tabindex="-1">DX and Ease of development/deployment <a class="header-anchor" href="#dx-and-ease-of-development-deployment" aria-hidden="true">#</a></h2><p>If you are using Vercel to deploy your website, then adding a new Serverless Function is as easy as adding a new NodeJS Express-like script (or written in a different language script) under <code>/api</code> folder. Vercel Serverless functions also work in the local dev environment out-of-the-box. Vercel achieves great Developer Experience (DX) here.</p><p>If you use Vercel for website deployment, but want to use Cloudflare Workers for Serverless (like me), then you need to learn and deal with many more things:</p><ul><li>how to write the script and what API is available</li><li>how Cache works and should you customize it or automatic settings are enough</li><li>how to set up automatic deployments from a repository</li><li>how to organize Functions in the repository</li><li>should you use and set up a custom domain or the one provided by Cloudflare is enough</li></ul><p>Cloudflare provides really great documentation with many easy-to-follow examples and &quot;Starters&quot; (GitHub repositories) for different use cases. It also provides a <a href="https://developers.cloudflare.com/workers/learning/playground" target="_blank" rel="noopener noreferrer">Playground</a> to preview, debug and develop your functions. I find it very helpful and use it frequently.</p><p><img src="/blog/assets/cf-playground.220e823a.png" alt=""></p><h2 id="cache-management" tabindex="-1">Cache management <a class="header-anchor" href="#cache-management" aria-hidden="true">#</a></h2><p>Cache in Vercel and Cloudflare Workers is always local to the Region (Data Center).</p><p><strong>Vercel&#39;s</strong> cache configuration is limited to setting a <code>Cache-Control</code> header on the response of the Function. Vercel recommends here not to use Browser caching, but rely on Vercel&#39;s Network cache. Hence configuration comes down mostly to setting the cache time. Moreover, there is a bunch of restrictions regarding when the cache can be used (e.g. response status codes and request methods, request headers).</p><p>When providing a cached response, Vercel doesn&#39;t give a chance to the Function to execute and do any changes to the cached response or, for example, log the request.</p><p>With every new deployment Vercel automatically invalidates the Cache. Hence, if there is a need to invalidate the cache, developers need to redeploy their application.</p><p><strong>Cloudflare</strong> provides a much more flexible and granular cache configuration and has a different mental model about how caching should work.</p><p>Most of the time Functions don&#39;t have heavy computations, they spend their time mostly awaiting the responses from subrequests.</p><p>Recognizing that, Cloudflare runs Functions on every request and provides automatic caching for outbound Function subrequests. Developers can modify subrequests caching behavior by providing <a href="https://developers.cloudflare.com/workers/runtime-apis/request#requestinitcfproperties" target="_blank" rel="noopener noreferrer">certain configuration</a>.</p><p>I think that running a Function every time on every request is a very important feature that distinguishes Cloudflare Workers from Vercel. It allows you to log stuff to third-party services and have some analytics.</p><p>Cloudflare covers also the case when a Function does have heavy computations. Developers have access to Cache API to store Function responses and use it in future requests. Developers are free to define how and when to cache, whet to use and when to delete the cached value, free to modify the cached value before sending the response. Cloudflare provides good documentation and <a href="https://developers.cloudflare.com/workers/examples" target="_blank" rel="noopener noreferrer">examples</a> to start from.</p><div class="language-javascript"><pre><code><span class="token keyword">async</span> <span class="token keyword">function</span> <span class="token function">handleRequest</span><span class="token punctuation">(</span><span class="token parameter">event</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">const</span> request <span class="token operator">=</span> event<span class="token punctuation">.</span>request<span class="token punctuation">;</span>
  <span class="token keyword">const</span> cacheUrl <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">URL</span><span class="token punctuation">(</span>request<span class="token punctuation">.</span>url<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">// Construct the cache key from the cache URL</span>
  <span class="token keyword">const</span> cacheKey <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Request</span><span class="token punctuation">(</span>cacheUrl<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> request<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">const</span> cache <span class="token operator">=</span> caches<span class="token punctuation">.</span>default<span class="token punctuation">;</span>

  <span class="token comment">// Check whether the value is already available in the cache</span>
  <span class="token comment">// if not, you will need to fetch it from origin, and store it in the cache</span>
  <span class="token comment">// for future access</span>
  <span class="token keyword">let</span> response <span class="token operator">=</span> <span class="token keyword">await</span> cache<span class="token punctuation">.</span><span class="token function">match</span><span class="token punctuation">(</span>cacheKey<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>response<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// If not in cache, get it from origin</span>
    response <span class="token operator">=</span> <span class="token keyword">await</span> <span class="token function">fetch</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// Must use Response constructor to inherit all of response&#39;s fields</span>
    response <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Response</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// Cache API respects Cache-Control headers. Setting s-max-age to 10</span>
    <span class="token comment">// will limit the response to be in cache for 10 seconds max</span>

    <span class="token comment">// Any changes made to the response here will be reflected in the cached value</span>
    response<span class="token punctuation">.</span>headers<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">&#39;Cache-Control&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;s-maxage=10&#39;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// Store the fetched response as cacheKey</span>
    <span class="token comment">// Use waitUntil so you can return the response without blocking on</span>
    <span class="token comment">// writing to cache</span>
    event<span class="token punctuation">.</span><span class="token function">waitUntil</span><span class="token punctuation">(</span>cache<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>cacheKey<span class="token punctuation">,</span> response<span class="token punctuation">.</span><span class="token function">clone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
  <span class="token keyword">return</span> response<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre></div><div class="code-descr">Code snippet taken from <a href="https://developers.cloudflare.com/workers/examples/cache-api">https://developers.cloudflare.com/workers/examples/cache-api</a></div><h2 id="key-value-data-store" tabindex="-1">Key-value Data Store <a class="header-anchor" href="#key-value-data-store" aria-hidden="true">#</a></h2><p>Cloudflare Serverless Functions have a really nice distinct feature - they have access to a global, low-latency, key-value <a href="https://developers.cloudflare.com/workers/learning/how-kv-works" target="_blank" rel="noopener noreferrer">data store</a>. Changes to that store are propagated to all other edge locations and become globally visible. That store doesn&#39;t replace a database but works nicely in some cases. I think of it as a globally available Cache. That store can also be prepopulated manually (via CLI interface) or during deployment. Developers can define a lifetime for values there to make sure they are automatically discarded at a certain moment.</p><h2 id="programming-languages" tabindex="-1">Programming Languages <a class="header-anchor" href="#programming-languages" aria-hidden="true">#</a></h2><p><strong>Cloudflare</strong> supports only one runtime - Chrome&#39;s <a href="https://v8.dev/" target="_blank" rel="noopener noreferrer">V8</a>. Hence, it supports natively JavaScript. For many languages like Kotlin, PHP, Python it&#39;s possible to compile programs to JavaScript. So developers can write Functions in those languages as well, they just need to have a compilation to JavaScript step.</p><p>Cloudflare doesn&#39;t stop there and provides <a href="https://blog.cloudflare.com/webassembly-on-cloudflare-workers/" target="_blank" rel="noopener noreferrer">support for Web Assembly</a> as well. It means that also compiled languages like C, C++, Rust, and Go can be used to write Functions.</p><p><strong>Vercel</strong> <a href="https://vercel.com/docs/runtimes?query=runtime#official-runtimes" target="_blank" rel="noopener noreferrer">officially supports</a> 4 different language runtimes - NodeJS, Go, Python and Ruby.</p><p>Vercel also allows creating custom runtimes with different languages. There are some community runtimes available that have official Vercel&#39;s <a href="https://vercel.com/docs/runtimes?query=runtime#advanced-usage/community-runtimes" target="_blank" rel="noopener noreferrer">recommendation</a>: Bash, Deno, PHP, and Rust.</p><h2 id="scheduled-invocations-cron" tabindex="-1">Scheduled Invocations (Cron) <a class="header-anchor" href="#scheduled-invocations-cron" aria-hidden="true">#</a></h2><p><strong>Cloudflare</strong> has <a href="https://developers.cloudflare.com/workers/platform/cron-triggers" target="_blank" rel="noopener noreferrer">built-in support</a> for scheduled invocations of Functions.</p><p><strong>Vercel</strong> doesn&#39;t have built-in support for scheduled tasks and <a href="https://vercel.com/docs/solutions/cron-jobs" target="_blank" rel="noopener noreferrer">recommends</a> using third-party services.</p><h2 id="logging-to-3rd-party-services" tabindex="-1">Logging to 3rd party services <a class="header-anchor" href="#logging-to-3rd-party-services" aria-hidden="true">#</a></h2><p>There is often a need to communicate to 3rd party services in a non-blocking way - you send a Response to the user and, in parallel, send data to some 3rd party services, for example, gather some statistical data.</p><p>The problem with Serverless Functions is that their lifetime is very limited and it might happen that the runtime shuts down before it handles the communication.</p><p><strong>Cloudflare</strong> provides a <a href="https://developers.cloudflare.com/workers/learning/fetch-event-lifecycle#waituntil" target="_blank" rel="noopener noreferrer"><code>waitUntil()</code></a> hook to notify the runtime to wait for tasks that run longer than the time it takes to send the response. It is used, for example, to write data to Cache.</p><div class="language-javascript"><pre><code><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>response<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token comment">// If not in cache, get it from origin</span>
  response <span class="token operator">=</span> <span class="token keyword">await</span> <span class="token function">fetch</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">// Must use Response constructor to inherit all of response&#39;s fields</span>
  response <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Response</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">// Cache API respects Cache-Control headers. Setting s-max-age to 10</span>
  <span class="token comment">// will limit the response to be in cache for 10 seconds max</span>

  <span class="token comment">// Any changes made to the response here will be reflected in the cached value</span>
  response<span class="token punctuation">.</span>headers<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">&#39;Cache-Control&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;s-maxage=10&#39;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">// Store the fetched response as cacheKey</span>
  <span class="token comment">// Use waitUntil so you can return the response without blocking on</span>
  <span class="token comment">// writing to cache</span>
  event<span class="token punctuation">.</span><span class="token function">waitUntil</span><span class="token punctuation">(</span>cache<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>cacheKey<span class="token punctuation">,</span> response<span class="token punctuation">.</span><span class="token function">clone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token keyword">return</span> response<span class="token punctuation">;</span>
</code></pre></div><div class="code-descr">Code snippet taken from <a href="https://developers.cloudflare.com/workers/examples/cache-api">https://developers.cloudflare.com/workers/examples/cache-api</a></div><p>In <strong>Vercel</strong>&#39;s Functions, I tried to set up logging errors to Sentry and logging data to some database, but it worked unpredictably - sometimes it worked, sometimes it didn&#39;t. I also got strange errors in logs. It took me time to realize that the problem was that the runtime stops working once the Response is sent.</p><blockquote><p>It is important to note that Serverless Functions, even while the underlying container is hot, cannot leave tasks running. If a sub-process is running by the time the response is returned, the entire container is frozen. When a new invocation happens, if the container is re-used, it is unfrozen, which allows sub-processes to continue running.</p></blockquote><p>I couldn&#39;t find any workaround for such a problem.</p><p>Another problem that I found with Vercel is that you can&#39;t really log all the requests to your Function and build analytics on top of it because Functions are not executed in case there is a cached response for the request. I couldn&#39;t find a solution for it. There is no such problem with Cloudflare because its Functions get always executed on every request.</p><h2 id="limits" tabindex="-1">Limits <a class="header-anchor" href="#limits" aria-hidden="true">#</a></h2><div class="info custom-block"><p class="custom-block-title">Update 2021-05-11</p><p>The recently released Cloudflare&#39;s <a href="https://blog.cloudflare.com/workers-unbound-ga/" target="_blank" rel="noopener noreferrer">Workers Unboud</a> solution extends the 50ms CPU limit to 30sec. You can find more information on the Cloudflare <a href="https://developers.cloudflare.com/workers/platform/limits#worker-limits" target="_blank" rel="noopener noreferrer">Limits</a> page.</p></div><table><thead><tr><th></th><th>Cloudflare <a href="https://developers.cloudflare.com/workers/platform/limits" target="_blank" rel="noopener noreferrer">(link)</a></th><th>Vercel <a href="https://vercel.com/docs/platform/limits" target="_blank" rel="noopener noreferrer">(link)</a></th></tr></thead><tbody><tr><td>Memory size</td><td>128 MB</td><td>1024 MB for Hobby plan and 3008 MB for Pro</td></tr><tr><td>Execution timeout</td><td>No limit on the real runtime for a Function script. Instead, there is a limit on the CPU runtime: 10ms on the free plan and 50ms on the Bundled plan. The time to fulfill subrequests doesn&#39;t count if there is no processing and CPU is idling.</td><td>10 sec for Hobby plan and 60 sec for Pro</td></tr><tr><td>Number of Functions</td><td>30</td><td>12 for Hobby plan and no limits for Free and Enterprise plans</td></tr><tr><td>Script size</td><td>1 MB after compression</td><td>50 MB</td></tr><tr><td>Function Regions</td><td>Functions are always deployed to all available regions. No limits here</td><td>1 region for Hobby and Pro plans. Multiple regions for Enterprise plans.</td></tr></tbody></table><h2 id="pricing" tabindex="-1">Pricing <a class="header-anchor" href="#pricing" aria-hidden="true">#</a></h2><div class="info custom-block"><p class="custom-block-title">Update 2021-05-11</p><p>With the introduction of <a href="https://blog.cloudflare.com/workers-unbound-ga/" target="_blank" rel="noopener noreferrer">Workers Unboud</a> solution Cloudflare changed their pricing model - the pricing now is based on the usage model of a particular worker. You can find more information on the Cloudflare <a href="https://developers.cloudflare.com/workers/platform/pricing#usage-models" target="_blank" rel="noopener noreferrer">Pricing</a> page.</p></div><p><strong>Cloudflare Workers</strong> are free to all, but subject to some limits, mainly reads/writes to Key-Value (KV) storage, limited KV storage (1 GB) and also CPU runtime limited to 10 ms.</p><p>Bundled plan for a minimum charge of $5/month includes everything that is in Free, plus increased CPU runtime (50 ms) and access to increased KV storage and reads/writes. The final price is defined by the real usage.</p><p>Check Cloudflare Workers&#39; <a href="https://developers.cloudflare.com/workers/platform/pricing" target="_blank" rel="noopener noreferrer">pricing page</a> for more details.</p><p><strong>Vercel</strong>&#39;s free plan is generous in terms of available resources (except for 1 region limitation), but it is restricted to <a href="https://vercel.com/docs/platform/fair-use-policy#commercial-usage" target="_blank" rel="noopener noreferrer">non-commercial usage</a> only.</p><p>Pro plan for $20/month per team member enables some team collaboration features and deployment from GitHub Organisations.</p><p>Enterprise plan enables multi-region Serverless Functions and &quot;Enterprise&quot; support.</p><p>All plans are subject to Vercel&#39;s <a href="https://vercel.com/docs/platform/fair-use-policy" target="_blank" rel="noopener noreferrer">Fair Use Policy</a>.</p><p>Check Vercel&#39;s <a href="https://vercel.com/pricing" target="_blank" rel="noopener noreferrer">pricing page</a> for more details.</p></div></div><div class="mt-8" data-v-f61783ce data-v-2f056962><hr data-v-2f056962><a href="/blog/" title="Home" class="text-2xl" data-v-2f056962>← all posts</a><h2 data-v-2f056962>Subscribe to the monthly newsletter</h2><div id="revue-embed" data-v-2f056962><div class="revue-form-footer" data-v-2f056962> By subscribing, you agree with Revue’s <a target="_blank" href="https://www.getrevue.co/terms" data-v-2f056962>Terms</a> and <a target="_blank" href="https://www.getrevue.co/privacy" data-v-2f056962>Privacy Policy</a>. </div><form action="https://www.getrevue.co/profile/moiva/add_subscriber" method="post" id="revue-form" name="revue-form" target="_blank" data-v-2f056962><div class="revue-form-group" data-v-2f056962><label for="member_email" style="display:none;" data-v-2f056962>Email address</label><input class="revue-form-field" placeholder="Your email address..." type="email" name="member[email]" id="member_email" data-v-2f056962></div><div class="revue-form-actions" data-v-2f056962><input type="submit" value="Subscribe" name="member[subscribe]" id="member_submit" data-v-2f056962></div></form></div></div></main></article></div><footer class="pt-5 my-0 text-base text-white pb-7 font-extralight bg-primary flex-shrink-0" data-v-af44d146><div class="container px-10 antialiased sm:px-24 content" data-v-af44d146><div class="w-full mx-auto lg:w-9/12 xl:w-2/4" data-v-af44d146><div class="flex items-center justify-center mb-4" data-v-af44d146><span data-v-af44d146>Made with</span><span style="margin:0 4px;" data-v-af44d146><svg xmlns="http://www.w3.org/2000/svg" style="width:20px;height:20px;" viewBox="0 0 20 20" fill="currentColor" data-v-af44d146><path fill-rule="evenodd" d="M3.172 5.172a4 4 0 015.656 0L10 6.343l1.172-1.171a4 4 0 115.656 5.656L10 17.657l-6.828-6.829a4 4 0 010-5.656z" clip-rule="evenodd" data-v-af44d146></path></svg></span><span data-v-af44d146>by</span><a class="primary-link" href="https://alexei.me" target="_blank" rel="noopener" style="margin-left:4px;" data-v-af44d146>Alexey Antipov</a></div><div class="flex items-center justify-between text-xl" data-v-af44d146><a class="primary-link" target="_blank" href="/" data-v-af44d146>Moiva.io</a><a class="primary-link" target="_blank" href="/about/" data-v-af44d146>About</a><a class="primary-link" target="_blank" href="/catalog/" data-v-af44d146>Catalog</a><a class="primary-link" href="/blog/" data-v-af44d146>Blog</a></div><div class="flex flex-wrap items-center justify-around mt-6 text-xl" data-v-af44d146><a class="primary-link flex items-center" href="https://github.com/aantipov/moiva" rel="noopener" target="_blank" data-v-af44d146><svg xmlns="http://www.w3.org/2000/svg" class="w-5 h-5 fill-current text-white mr-1" style="max-width:50px;max-height:50px;" role="img" aria-label="GitHub icon" viewBox="0 0 24 24" data-v-af44d146><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12" data-v-af44d146></path></svg> GitHub</a><a class="primary-link flex items-center" href="https://twitter.com/_aantipov" target="_blank" rel="noopener" data-v-af44d146><svg xmlns="http://www.w3.org/2000/svg" class="w-5 h-5 fill-current text-white mr-1" style="max-width:50px;max-height:50px;" role="img" aria-label="Twitter icon" viewBox="0 0 24 24" data-v-af44d146><g data-v-af44d146><path d="M23.643 4.937c-.835.37-1.732.62-2.675.733a4.67 4.67 0 0 0 2.048-2.578a9.3 9.3 0 0 1-2.958 1.13a4.66 4.66 0 0 0-7.938 4.25a13.229 13.229 0 0 1-9.602-4.868c-.4.69-.63 1.49-.63 2.342A4.66 4.66 0 0 0 3.96 9.824a4.647 4.647 0 0 1-2.11-.583v.06a4.66 4.66 0 0 0 3.737 4.568a4.692 4.692 0 0 1-2.104.08a4.661 4.661 0 0 0 4.352 3.234a9.348 9.348 0 0 1-5.786 1.995a9.5 9.5 0 0 1-1.112-.065a13.175 13.175 0 0 0 7.14 2.093c8.57 0 13.255-7.098 13.255-13.254c0-.2-.005-.402-.014-.602a9.47 9.47 0 0 0 2.323-2.41l.002-.003z" data-v-af44d146></path></g></svg> Twitter</a></div></div></div></footer></div></div>
    <script>__VP_HASH_MAP__ = JSON.parse("{\"2021-03-update-migration-to-cloudflare-workers_index.md\":\"c325f9dc\",\"2021-04-update-github-stars-chart_index.md\":\"2a4902c3\",\"2021-05-update_index.md\":\"5d29226a\",\"2021-06-update-improved-table-view-seo-fixes_index.md\":\"4e1a7550\",\"2021-07-update-new-metric-status_index.md\":\"d093f526\",\"2021-08-update-share-charts-new-suggestions_index.md\":\"3c801a3c\",\"2021-09-update--actions-in-table-charts_index.md\":\"3f6e5b7e\",\"2021-10-update_index.md\":\"944da027\",\"2021-12-update_index.md\":\"b2812e84\",\"2021-q1-report-end-to-end-testing-frameworks_index.md\":\"7f451f56\",\"2021-q1-report-js-build-tools-bundlers_index.md\":\"b2c45bb6\",\"2021-q1-report-js-jamstack_index.md\":\"30b2739a\",\"2021-q1-report-js-testing-libraries_index.md\":\"f3f99fd7\",\"2021-q1-report-state-management_index.md\":\"96952259\",\"2021-q1-state-of-js-frameworks_index.md\":\"a8881f30\",\"2022-01-update_index.md\":\"dc775965\",\"index.md\":\"c2be3831\",\"the-missing-migration-guide-from-vue-cli-to-vite_index.md\":\"e802a5cf\",\"universal-tool-to-evaluate-discover-compare-software_index.md\":\"39eb1cfe\",\"vercel-serverless-functions-vs-cloudflare-workers_index.md\":\"8e5a506b\"}")</script>
    <script type="module" async src="/blog/assets/app.c9d8ac17.js"></script>
    
  </body>
</html>